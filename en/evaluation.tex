\chapter{Evaluation}\label{evaluation}
In this chapter, we will evaluate our rhyme detector. In the beginning, we will compare its performance with RhymeTagger. Then we will use it to analyze our dataset and calculate statistics about song lyrics.

\section{Performance evaluation on schemes}
To evaluate the quality of our Rhyme Detector, we will compare its rhyme scheme predictions with \gls{gold_data}. We have two annotated datasets we can use -- Chicago Rhyming Poetry Corpus and  the annotated subset of our own dataset.
\MP{Takže dev set, nebo test set?}
We will also compare our performance with that of RhymeTagger.

\subsection{Taggers}
We will be comparing different variants of the taggers to also evaluate the influence some factors have on the performance. The variants are following:
\begin{itemize}
	\item \textbf{RhymeTagger} -- the original version of RhymeTagger, as it was trained by Plecháč.
	\item \textbf{RhymeTagger -- fine-tuned} -- RhymeTagger trained on one third of our data.
	\MP{Proč jen třetina? Předpokládám, že trénování RhymeTaggeru bylo pomalé (pomalejší než Rhyme Detectoru?) či vyžadovalo víc paměti, než jste měla k dispozici.
	Je-li to tak, napište to sem, třeba do poznámky pod čarou.
	Metodologicky ideální by bylo ještě natrénovat i váš Detector jen na té třetině, aby to bylo porovnatelné.}
	\MP{To jste trénovala zcela znovu, že? Tedy se nejedná o fine-tuning, ale training from scratch.
	Tedy by šlo RhymeTagger přejmenovat na RhymeTagger(ChicagoRPC) a fine-tuned na RhymeTagger(Genius$\frac{1}{3}$), kde ChicagoRPC a Genius by se zadefinovalo jako názvy těch datasetů,
	respektive jejich trénovacích částí.}
	\item \textbf{Rhyme Detector} -- our detector, as described in Chapter \ref{chap-rhyme-analysis}, with \added{the} default settings
	\MP{Kolik iterací EM to tedy bylo? A dosáhlo to opravdu konvergence?}
	\item \textbf{Rhyme Detector -- experiment} -- an experimental version of our detector\deleted{,} that was not trained with \added{the} EM algorithm, but instead the matrix was created by counting the co-occurrences in the data and using their probabilities
	\MP{Pokud si pamatuji, tak zde jste ale co-occurrences nepočítala z rhyme fellows,
	ale ze všech adeptů (tedy rhyme candidates) v rámci daného window.
	}
	\item \textbf{Rhyme Detector -- 1 iteration} -- our detector after \added{the} 1\textsuperscript{st} iteration of \replaced{the EM algorithm}{training}
	\item \textbf{Rhyme Detector -- perfect} -- our detector \replaced{configured to}{using the setting of} only finding perfect rhymes -- the co-occurrence matrix is an identity matrix
\end{itemize}

\subsection{Scores}
To evaluate the performance, we need to find an appropriate measure that could compare the gold scheme with the prediction. This task may seem easy at first, but we need to be careful because the straight-forward approach of comparing the schemes letter by letter would not work. If the prediction made an error in the beginning it would alphabetically shift the rest of the scheme and it would no longer match with the gold data.

\paragraph{Last Index Score (LI)} To solve this problem, we propose Last Index Score (LI score). The idea is to convert the scheme from letter representation to last rhyme's index representation. This means for each line, we will use the index of the last line that rhymed with it. If the line does not have a rhyme, we will use index -1. With such representation, we can compare these \replaced{indices}{indexes} directly, independently from scheme letters, and the proportion of matching \replaced{indices}{indexes} will give us a score between 0 and 1. For an illustrative example, see Table \ref{LI_score_example}.
\MP{Dovolil jsem si přidat do tabulky sloupec line index a trochu přeformátovat}

% \begin{table}[h!]
% 	\centering
% 	\begin{tabular}{c c | c c}
% 		\multicolumn{2}{c |}{Straight-forward} &
% 		\multicolumn{2}{c }{Last Index}\\
% 		\hline
% 		Gold & Prediction & Gold & Prediction\\
% 		\hline
% 		\color{OliveGreen}a		&\color{OliveGreen}a		&\color{OliveGreen}-1		&\color{OliveGreen}-1	\\
% 		\color{Bittersweet}a		&\color{Bittersweet}b		&\color{Bittersweet}0		&\color{Bittersweet}-1	\\
% 		\color{Bittersweet}b		&\color{Bittersweet}c		&\color{OliveGreen}-1		&\color{OliveGreen}-1\\
% 		\color{Bittersweet}b		&\color{Bittersweet}c		&\color{OliveGreen}2		&\color{OliveGreen}2	\\
% 		\color{Bittersweet}c		&\color{Bittersweet}d		&\color{OliveGreen}-1		&\color{OliveGreen}-1	\\
% 		\color{Bittersweet}c		&\color{Bittersweet}d		&\color{OliveGreen}4		&\color{OliveGreen}4	\\
% 		\color{Bittersweet}b		&\color{Bittersweet}c		&\color{OliveGreen}3		&\color{OliveGreen}3	\\
% 		\color{Bittersweet}b		&\color{Bittersweet}c		&\color{OliveGreen}6		&\color{OliveGreen}6	\\
% 		\midrule
% 		\multicolumn{2}{c |}{SCORE: 0.125} &
% 		\multicolumn{2}{c }{SCORE: 0.875}\\
% 	\end{tabular}
% 	\caption[Comparison of the straight-forward approach and LI score.]{Comparison of the straight-forward approach and LI score.}
% 	\label{LI_score_example}
% \end{table}
\begin{table}[h!]
	\centering
	\begin{tabular}{c cc cc}\toprule
	 line &
		\multicolumn{2}{c}{Straight-forward} &
		\multicolumn{2}{c}{Last Index}\\\cmidrule(r){2-3}\cmidrule(l){4-5}
      index    & Gold & Prediction & Gold & Prediction\\\midrule
		0 & \color{OliveGreen}a		&\color{OliveGreen}a		&\color{OliveGreen}-1		&\color{OliveGreen}-1	\\
		1 & \color{Bittersweet}a		&\color{Bittersweet}b		&\color{Bittersweet}0		&\color{Bittersweet}-1	\\
		2 & \color{Bittersweet}b		&\color{Bittersweet}c		&\color{OliveGreen}-1		&\color{OliveGreen}-1\\
		3 & \color{Bittersweet}b		&\color{Bittersweet}c		&\color{OliveGreen}2		&\color{OliveGreen}2	\\
		4 & \color{Bittersweet}c		&\color{Bittersweet}d		&\color{OliveGreen}-1		&\color{OliveGreen}-1	\\
		5 & \color{Bittersweet}c		&\color{Bittersweet}d		&\color{OliveGreen}4		&\color{OliveGreen}4	\\
		6 & \color{Bittersweet}b		&\color{Bittersweet}c		&\color{OliveGreen}3		&\color{OliveGreen}3	\\
		7 & \color{Bittersweet}b		&\color{Bittersweet}c		&\color{OliveGreen}6		&\color{OliveGreen}6	\\
		\midrule
		& \multicolumn{2}{c}{SCORE: 0.125} &
		\multicolumn{2}{c}{SCORE: 0.875}\\\bottomrule
	\end{tabular}
	\caption[Comparison of the straight-forward approach and LI score.]{Comparison of the straight-forward approach and LI score.}
	\label{LI_score_example}
\end{table}


\paragraph{ARI score} If we look at the rhyme scheme, we can notice that scheme letters can equally be represented as line cluster. All lines that share a scheme letter form one cluster \replaced{(a rhyme group)}{together}, and every line that does not have a rhyme is a cluster of its own. Adjusted Rand\deleted[comment={je to pojmenované po panu Randovi}]{om} Index \added{(ARI)} Score\footnote{\url{https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index}} is a corrected-for-chance statistical measure of similarity between two data clusterings. We can therefore convert the schemes to use a unique letter for each non-rhyming line and use this score to evaluate the similarity of the schemes. 

\paragraph{} For these two scores, we include both micro and macro average on the dataset. Macro average is the average of all song scores, while micro average is the average of song scores weighted by the number of lines in each song.


\subsection{Comparison of the results}
We calculated the aforementioned scores for all variants of tagger\added{s} and summed up the results in Tables \ref{reddy_eval} and \ref{my_eval}. 

They both performed better on the Chicago Poetry Corpus (see Table \ref{reddy_eval}). Surprisingly, our detector performed the best after 1\textsuperscript{st} iteration, but the difference is not \deleted{very} significant.
\MP{Signifikance je přesně matematicky definovaná, měl by se uvést i test, kterým se počítala a alpha.
Nelze psát very/more significant.
Pokud nebyla exaktně měřena signifikance, lze o tom rozdílu psát třeba substantial nebo large.}

\begin{table}[h!]
	\centering
	\begin{tabular}{l | r r | r r}
	&	\multicolumn{2}{c |}{ARI} &
		\multicolumn{2}{c }{LI}\\
	\cline{2-5}	
	&macro &  micro  & macro  & micro \\
	\midrule
	RhymeTagger & \textbf{0.9463} & \textbf{0.9384} & \textbf{0.9635} & \textbf{0.9534} \\
	RhymeTagger fine-tuned& 0.8819 & 0.8822 & 0.9282 & 0.9202 \\
	\midrule
	Rhyme Detector & 0.9040 & 0.8915 & 0.9413 & 0.9272 \\
	Rhyme Detector -- experiment & 0.9025 & 0.8906 & 0.9406 & 0.9272 \\
	Rhyme Detector -- 1 iteration & \textbf{0.9066} &\textbf{0.8926} &\textbf{0.9426} &\textbf{0.9277} \\
	Rhyme Detector -- perfect &0.8824 &0.8732 &0.9293 &0.9149 \\
 \end{tabular}
	\caption{Evaluation of taggers on Chicago Rhyming Poetry Corpus.}
	\label{reddy_eval}
\end{table}

On our dataset (Table \ref{my_eval}), however, the best performing was the experiment variant.
\MP{No, celkově nejlepší byl ve všech 4 evaluacích původní RhymeTagger.}
Surprisingly, the fine-tuned RhymeTagger performed worse than the original pre-trained version. The possible cause is the nature of our data -- song lyrics have a significantly smaller percentage of rhymes than poems, so the collocations approach might not work as well for our dataset. This might also be the reason why our detector, trained only on our data, does not perform as well as RhymeTagger.
\MP{Nabízí se otázka, proč jste tedy nenatrénovala Váš detector na ChicagoRPC.
Můžete té otázce předejít, že to poznamenáte jako future work.
Případně to můžete ignorovat a čekat, zda se Vás na to nezeptá oponent
a nestihnete to ještě do obhajoby.}
\MP{Těch otázek k diskutování se nabízí více.
Např. nemáte-li v tom EM chybu, když to nikdy není nejlepší z Vašich verzí.
A obecně: čím jsou způsobené ty rozdíly.
Teď už na tyto otázky odpovědi nalézt nestihneme.
Je ale možné, že se na něco takového zeptám ve svém posudku.}

\begin{table}[h!]
	\centering
	\begin{tabular}{l | r r | r r}
		&	\multicolumn{2}{c |}{ARI} &
		\multicolumn{2}{c }{LI}\\
		\cline{2-5}	
		&macro &  micro  & macro  & micro \\
		\midrule
	RhymeTagger &  \textbf{0.6519} &\textbf{0.6627} &\textbf{0.8021} & \textbf{0.8139} \\
	RhymeTagger fine-tuned& 0.6309 &0.6443 &0.7883 &0.804 \\
	\midrule
	Rhyme Detector & 0.6157 &0.6306 &0.7716 &0.7861 \\
	Rhyme detector -- experiment &\textbf{0.6359} &\textbf{0.6571} &\textbf{0.7866} &0.802 \\
	Rhyme detector -- 1 iteration& 0.6096 &0.6256 &0.7682 &0.7832 \\
	Rhyme Detector -- perfect &0.6224 &0.641 &0.7838 &\textbf{0.803}\\
	\end{tabular}
	\caption{Evaluation of taggers on \replaced[comment={nebo to nazvěte třeba Genius-Test}]{our}{my} annotated dataset.}
	\label{my_eval}
\end{table}



\section{Statistical analysis of the dataset}
Although our detector was trained on our dataset, it was unsupervised so we can still use our detector to evaluate this dataset and give us new statistical information about a large number of song lyrics. We ran rhyme detection for nearly half a million songs and summed up the results in Tables \ref{rhyme_line_stats}, \ref{rhyme_types_perc}, \ref{rhyme_group_size}, \ref{song_rating_stats}, and \ref{rhyme_stats}. In the rest of this section, we will look at them more closely and discuss the outcome that might be surprising, or the opposite, confirms the specific  characteristics of a particular genre. Extreme values are emphasized in the tables. Keep in mind, that the lyrics and their classification to genres is crowd-sourced and might be biased.
% \begin{table}[h!]
% 	\centering
% 	\begin{tabular}{l | r r r r r} 	
% 		Genre & 			Pop & 		Rap & 		Rock & 		R\&B & 		Country\\ 
% 		\midrule
% 		 Total songs& 293,679 & 99,185& 34,372& 5,125& 3,816 \\
% 		Total lines& 9,104,273 &5,661,603& 1,087,245& 225,344& 121,207 \\ 
% 		Total rhyming lines& 4,536,554& 2,849,905& 523,879& 117,862& 61,142 \\ 
% 		 Rhyming lines (\%) & 49.8\%& 50.3\%& 48.2\%& 52.3\%& 50.4\%  \\
% 		 Average lines per song & 31.001 & \textbf{57.081} & 31.632 & 43.970 & 31.763  \\
% 
% 	\end{tabular}
% 	\caption{General statistics about dataset and rhymes, per genre.} 
% 	\label{rhyme_line_stats}
% \end{table}
\MP{Opět jsem si dovolil předělat tabulku, tentokrát včetně transpozice,
aby ve sloupcích pod sebou byla čísla stejného typu.}
\begin{table}[h!]\centering
\begin{tabular}{l  r r r r r}\toprule
       &         & \multicolumn{4}{c}{Lines} \\\cmidrule(l){3-6}
\pulrad{Genre}& \pulrad{Songs}
                 & total     & avg per song  & rhyming   & (\%) \\\midrule
Pop    & 293,679 & 9,104,273 & 31.001        & 4,536,554 & 49.8 \\
Rap    &  99,185 & 5,661,603 &\textbf{57.081}& 2,849,905 & 50.3 \\
Rock   &  34,372 & 1,087,245 & 31.632        &   523,879 & 48.2 \\
R\&B   &   5,125 &   225,344 & 43.970        &   117,862 & 52.3 \\
Country&   3,816 &   121,207 & 31.763        &    61,142 & 50.4 \\\bottomrule
\end{tabular}
\caption{General statistics about dataset and rhymes, per genre.} 
\label{rhyme_line_stats}
\end{table}

In Table \ref{rhyme_line_stats}, we sum up the basic information for all genres including the portion of lines that rhyme and we can already see some interesting results. Surprisingly, the highest portion of rhyming lines is in the R\&B genre. We do not see any characteristic of this genre that could cause this. However, it is not a big difference and maybe having more examples from this genre would make it less significant. 

We can see that throughout genres typically only about half of the lines rhyme. This shows, that rhyming in songs is not as essential as perhaps in poems. Predictably, rap has a significantly higher average number of lines per song which confirms the fact that this genre is more talkative. What may be unexpected is that it is nearly two times more than for the other genres -- only R\&B slightly stands out but that is not a surprise because it has been influenced by rap.

\begin{table}[h!]
	\centering
	\begin{tabular}{l | r r r r r} 	
		Genre & 			Pop & 		Rap & 		Rock & 		R\&B & 		Country\\ 
		\midrule
		Perfect masculine &	72.5& 	\textbf{58.2}& 	72.3& 	70.2& 	73.5 \\
		Perfect feminine &	7.9&		8.4& 		7.7& 		8.5& 		6.2 \\
		Perfect dactylic & 	0.7 &		0.5 & 	0.9 &		0.5& 		0.3 \\  
		Imperfect & 		12.0& 	\textbf{22.3} & 	12.1 & 	13.5 & 	12.2 \\
		Forced &  			6.9 & 	\textbf{10.6} & 	7.0 & 	7.3 &		7.8 \\
	\end{tabular}
	\caption{Percentage of different rhyme types from all rhymes in the dataset, per genre.} 
	\label{rhyme_types_perc}
\end{table}

Next, Table \ref{rhyme_types_perc} shows distribution of different rhyme types. It did not come as a surprise that the most common type, by a long shot, is perfect masculine. The reasons behind this might be several -- not only has perfect match the strongest effect melodically, it is also the easiest to come up with, and makes the lyrics easy to remember. The multi-syllable perfect rhymes have a lower percentage as longer matching word pairs are rather rare. The amount of forced rhymes might be higher in reality because their detection is the hardest and they might be missed more often.

Concerning rhyme types, we see that genres are generally not very different, except for rap. Rap is very unique with rhymes, its artists are known for playing with them more creatively, using \gls{internal_rhyme}s, consonance, and assonance more often. They frequently play with emphasis what can be seen as a rapid increase in imperfect rhymes. There are more forced rhymes as well and perfect rhymes are decreased as a result.

\begin{table}[h!]
	\centering
	\begin{tabular}{l | r r r r r} 	
		Genre & 			Pop & 		Rap & 		Rock & 		R\&B & 		Country\\ 
		\midrule
		2-syllable rhymes & 91.1& 90.3& 91.1& 90.6 & 93.3\\
		5-syllable rhymes& 8.2& 9.2& 8.0& 8.9& 6.4  \\
		8-syllable rhymes& 0.7& 0.5& 0.9& 0.5& 0.3 \\
		Perfect sound match & 93.1&\textbf{ 89.4}& 93.0& 92.7& 92.2  \\
		Stress moved & 14.5& \textbf{28.3}& 14.5& 16.5& 14.8 \\
		
	\end{tabular}
	\caption{Statistics about rhyme properties in general, disregarding rhyme types, in percentage from total rhymes.} 
	\label{rhyme_stats}
\end{table}

Table \ref{rhyme_stats} is quite similar to the previous table, but by counting syllables regardless of rhyme type, and evaluating sound match and stress separately, it offers us a little bit different angle. By seeing that the percentages of 8-syllable rhymes match the percentages we have seen in Table \ref{rhyme_types_perc}, we can assume that 8-syllable rhymes might be exclusively perfect. The decreased match in sound and increased moving of stress in rap confirm the unique properties of rap we have seen previously.

A slightly increased percentage of 2-syllable in country may be noteworthy but we see no significant properties of country that could support this as a general claim.

\begin{table}[h!]
	\centering
	\begin{tabular}{l | r r r r r} 	
		Genre & 			Pop & 		Rap & 		Rock & 		R\&B & 		Country\\ 
		\midrule
		Average groups per song& 6.134 &\textbf{11.484} &6.091 &8.620 &6.676  \\
		Average groups per 100 lines &19.787 &20.119 &19.255 &19.605 &\textbf{21.018} \\
		Max groups per song & 169 &224 & 81 & 48 &98\\
		Average group size & 2.518 &2.502 &2.502 &2.668 &\textbf{2.400} \\
		Max group size & 159 &98 & 68 & 42 & 24\\
	\end{tabular}
	\caption{Statistics about rhyme group size per genre.} 
	\label{rhyme_group_size}
\end{table}

Table \ref{rhyme_group_size} summarizes statistics concerning size of rhyme groups. We can observe nearly double average size for rap compared to other genres, which directly corresponds to nearly double average song length, as we have seen in Table \ref{basic_stats}. 

An interesting observation can be made for country -- average number of rhyme groups per 100 lines is slightly higher than for other genres. This corresponds with average group size being lower -- obviously country tends to contain more and smaller rhymes groups. It would be interesting to know, whether this is only a property of our dataset or a property of country music in general. Although maximum group size does not tell us any general information about the group because it may only be an outlier, but it is still interesting to see, that this number is again the smallest for country.

\begin{table}[h!]
	\centering
	\begin{tabular}{l | r r r r r} 	
		Genre & 			Pop & 		Rap & 		Rock & 		R\&B & 		Country\\ 
		\midrule
		Average song rating& 0.432 & \textbf{0.599} &0.420 &0.520 &0.456  \\
		Median & \textbf{0.521} & 0.380 &0.357 &0.235 & 0.269\\
	\end{tabular}
	\caption{Song rating per genre.} 
	\label{song_rating_stats}
\end{table}

Looking at average and median ratings in Table \ref{song_rating_stats}, we can observe two curious extremes -- rap having the highest average rating and pop with the highest median rating. Rap leading in the average, but this dominance not being translated into median, tells us that there must be some extremely high rated songs that pulled up the average. Although we did not predict this result, it shows that some artists probably took the importance of rhyme in rap very seriously and elaborately incorporated it densely into their lyrics.

Highest median in pop shows that many pop songs are filled with more rhymes what can be explained by their strong tendency to be memorable. However, it seems that there are some low extremes that pulled the average rating down.
